# ğŸŒ AI Cloud Governance Platform

A unified multi-cloud AI governance platform that routes requests across **6 AI providers**, tracks costs, latency, and token usage, and provides a real-time analytics dashboard.

> Built as part of the **Joint Cloud Initiative** â€” demonstrating how organizations can govern, monitor, and optimize AI workloads across multiple cloud providers.

---

## ğŸš€ Features

- **Unified `/chat` API** â€” Single endpoint that routes to the best model per provider and use case
- **6 AI Providers Integrated**:
  | Provider | Gateway | Models |
  |---|---|---|
  | Google Gemini | Vertex AI + API Key | gemini-2.5-pro, flash, flash-lite |
  | OpenAI | Direct API | gpt-4o, gpt-4o-mini |
  | Meta Llama | Vertex AI (MaaS) | llama-3.3-70b |
  | Mistral AI | AWS Bedrock | mistral-small, mistral-large |
  | Amazon Nova | AWS Bedrock | nova-pro, nova-lite |
  | DeepSeek | Vertex AI (MaaS) | deepseek-v3.2, deepseek-r1 |

- **Model Matrix** â€” Automatically selects the best model based on provider + use case (reasoning, summarization, tool calling, etc.)
- **FinOps Cost Tracking** â€” Real-time cost calculation per request using `model-pricing.json`
- **Telemetry Logging** â€” All interactions logged to Supabase (provider, model, tokens, cost, latency)
- **Analytics Dashboard** â€” Interactive charts with provider-wise and use-case-wise breakdowns
- **Prompt Optimization Tips** â€” Context-aware suggestions to improve prompt quality

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend   â”‚â”€â”€â”€â”€â–¶â”‚  Backend API (FastAPI)                   â”‚
â”‚   (React +   â”‚     â”‚                                          â”‚
â”‚    Vite)     â”‚     â”‚  /api/chat  â”€â”€â–¶ Model Matrix â”€â”€â–¶ Router  â”‚
â”‚              â”‚â—€â”€â”€â”€â”€â”‚  /api/analytics â”€â”€â–¶ Supabase             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚           â”‚           â”‚
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                     â”‚ Vertex AI  â”‚ â”‚ OpenAI  â”‚ â”‚ AWS Bedrock â”‚
                     â”‚ (Google,   â”‚ â”‚ (Direct)â”‚ â”‚ (Mistral,   â”‚
                     â”‚  Meta,     â”‚ â”‚         â”‚ â”‚  Amazon)    â”‚
                     â”‚  DeepSeek) â”‚ â”‚         â”‚ â”‚             â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ Prerequisites

- **Python 3.10+** â€” [Download](https://www.python.org/downloads/)
- **Node.js 18+** â€” [Download](https://nodejs.org/)
- **Google Cloud SDK (`gcloud`)** â€” [Install Guide](https://cloud.google.com/sdk/docs/install)
- **Git** â€” [Download](https://git-scm.com/)

---

## âš¡ Setup Guide (Step by Step)

> **Note:** If you already have the `.env` file and project access shared with you, skip straight to Step 1.

### Step 1 â€” Install Google Cloud SDK

Download and install from: https://cloud.google.com/sdk/docs/install

After installation, **restart your terminal**, then verify:
```bash
gcloud --version
```

### Step 2 â€” Authenticate with Google Cloud

```bash
# Login to your Google account
gcloud auth login

# Set up Application Default Credentials (ADC) â€” this is REQUIRED for Vertex AI
gcloud auth application-default login

# Set the project (ask the project owner for the Project ID)
gcloud config set project YOUR_PROJECT_ID
```

> âš ï¸ **`gcloud auth application-default login` is critical.** Without it, Meta Llama and DeepSeek calls will fail because they use OAuth2 tokens via Vertex AI.

### Step 3 â€” Clone & Install

```bash
# Clone the repository
git clone https://github.com/your-username/AI_CLOUD_GOVERNANCE.git
cd AI_CLOUD_GOVERNANCE

# Backend setup
cd backend
python -m venv .venv
.venv\Scripts\activate        # Windows
# source .venv/bin/activate   # Mac/Linux
pip install -r requirements.txt

# Place the .env file (get it from the project owner)
# Copy the shared .env file into the backend/ folder

# Frontend setup
cd ../frontend
npm install
```

### Step 4 â€” Run

**Terminal 1 â€” Backend:**
```bash
cd backend
.venv\Scripts\activate
python -m uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

**Terminal 2 â€” Frontend:**
```bash
cd frontend
npm run dev
```

Open **http://localhost:5173** in your browser ğŸš€

### â“ Troubleshooting

| Issue | Fix |
|---|---|
| `google.auth.exceptions.DefaultCredentialsError` | Run `gcloud auth application-default login` again |
| `Meta Llama / DeepSeek 404 error` | Ensure the models are enabled in [Vertex AI Model Garden](https://console.cloud.google.com/vertex-ai/model-garden) |
| `OPENAI_API_KEY not set` | Make sure the `.env` file is in the `backend/` folder |
| `Module not found` | Make sure you activated the virtual environment |

---

## ğŸ”‘ Environment Variables

Copy `backend/.env.example` to `backend/.env` and fill in your credentials:

| Variable | Description |
|---|---|
| `SUPABASE_URL` | Supabase project URL |
| `SUPABASE_KEY` | Supabase anon/service key |
| `GOOGLE_API_KEY` | Google AI API key |
| `GOOGLE_CLOUD_PROJECT` | GCP Project ID |
| `GOOGLE_CLOUD_LOCATION` | GCP region (e.g. `us-central1`) |
| `OPENAI_API_KEY` | OpenAI API key |
| `AWS_ACCESS_KEY_ID` | AWS IAM access key |
| `AWS_SECRET_ACCESS_KEY` | AWS IAM secret key |
| `AWS_REGION` | AWS region (e.g. `us-east-1`) |

> âš ï¸ **Never commit `.env` files.** The `.gitignore` is configured to exclude them.

---

## ğŸ“Š API Endpoints

| Method | Endpoint | Description |
|---|---|---|
| `POST` | `/api/chat` | Send a prompt to any AI provider |
| `GET` | `/api/analytics` | Get aggregated analytics summary |
| `GET` | `/api/analytics/history` | Get raw telemetry history |
| `GET` | `/docs` | Swagger UI (interactive API docs) |

### Chat Request Body
```json
{
  "provider": "Google",
  "use_case": "reasoning",
  "prompt": "Explain cloud governance in one sentence"
}
```

### Chat Response
```json
{
  "response": "Cloud governance is...",
  "provider": "Google",
  "model_id": "gemini-2.5-pro",
  "use_case": "reasoning",
  "metrics": {
    "input_tokens": 12,
    "output_tokens": 45,
    "cost": 0.000506,
    "latency_ms": 1423
  }
}
```

---

## ğŸ—‚ï¸ Project Structure

```
AI_CLOUD_GOVERNANCE/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/endpoints/     # chat.py, analytics.py
â”‚   â”‚   â”œâ”€â”€ core/              # config.py, model_matrix.py
â”‚   â”‚   â”œâ”€â”€ models/            # schemas.py (Pydantic)
â”‚   â”‚   â”œâ”€â”€ services/          # ai_service, pricing_service, supabase_service
â”‚   â”‚   â””â”€â”€ main.py            # FastAPI app
â”‚   â”œâ”€â”€ tests/                 # Provider test scripts
â”‚   â”œâ”€â”€ model-pricing.json     # Cost per million tokens
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env.example
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx            # Chat interface
â”‚   â”‚   â”œâ”€â”€ AnalyticsDashboard.jsx  # Analytics with Recharts
â”‚   â”‚   â””â”€â”€ data.js            # Model matrix & pricing data
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸ›¡ï¸ Security

- All API keys stored in `.env` (gitignored)
- OAuth2 token refresh for Vertex AI (Meta, DeepSeek)
- AWS IAM credentials for Bedrock
- CORS configured for frontend access
- No hardcoded credentials in source code

---

## ğŸ“„ License

This project is for educational and research purposes as part of the Joint Cloud Initiative.
